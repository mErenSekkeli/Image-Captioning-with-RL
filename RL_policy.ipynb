{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': '03577_0',\n",
       "  'sentence1': 'a big blue building has been built in the middle of the scene ',\n",
       "  'sentence2': 'the bareland has been replaced by a blue building and a big blue building has been built ',\n",
       "  'sentence3': 'two big blue buildings have been replaced by a blue building '},\n",
       " {'filename': '03577_1',\n",
       "  'sentence1': 'a small blue building has been constructed on the bareland at the corner of the scene ',\n",
       "  'sentence2': 'many trees have appeared in many parts of the scene ',\n",
       "  'sentence3': 'many green trees have been constructed on the bareland and the grassland '},\n",
       " {'filename': '03577_2',\n",
       "  'sentence1': 'a big building has been constructed in many parts of the scene ',\n",
       "  'sentence2': 'a blue building has been constructed in the green area ',\n",
       "  'sentence3': 'a big building has been constructed in the green area '},\n",
       " {'filename': '03577_3',\n",
       "  'sentence1': 'two blue buildings have been built in many parts of the scene ',\n",
       "  'sentence2': 'two blue buildings have been built at the corner of the scene ',\n",
       "  'sentence3': 'the trees have grown up in many parts of the scene '}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load_data import load_json_data\n",
    "\n",
    "# Load data\n",
    "data = load_json_data(\"data/result.json\", 1000, 1520)\n",
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2084, 2048), (2084, 2048))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load_data import load_extracted_features\n",
    "features_im1 = load_extracted_features(\"im1\")\n",
    "# features shape is (2084, 2048, 1, 1)\n",
    "features_im1 = features_im1.reshape((2084, 2048))\n",
    "\n",
    "features_im2 = load_extracted_features(\"im2\")\n",
    "features_im2 = features_im2.reshape((2084, 2048))\n",
    "\n",
    "features_im1.shape, features_im2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "def bert_encode(sentences, bert_model, tokenizer, device, batch_size=32):\n",
    "    bert_model.to(device)\n",
    "    bert_model.eval()  # Modeli değerlendirme modunda çalıştır\n",
    "\n",
    "    # Tüm cümleleri batch'ler halinde işle\n",
    "    all_sentence_embeddings = []\n",
    "    for i in tqdm.tqdm(range(0, len(sentences), batch_size), desc=\"BERT Encoding\"):\n",
    "        batch_sentences = sentences[i:i+batch_size]\n",
    "        encoded = tokenizer.batch_encode_plus(\n",
    "            batch_sentences,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoded['input_ids'].to(device)\n",
    "        attention_mask = encoded['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "            sentence_embeddings = outputs[0][:, 0, :]  # [CLS] token'ın çıktısını al\n",
    "            all_sentence_embeddings.extend(sentence_embeddings.cpu().numpy())\n",
    "\n",
    "    return np.array(all_sentence_embeddings)\n",
    "\n",
    "def collect_all_sentences(data):\n",
    "    all_sentences = []\n",
    "    sentence_lengths = []\n",
    "    for data_point in data:\n",
    "        sentences = data_point['sentences']\n",
    "        all_sentences.extend(sentences)\n",
    "        sentence_lengths.append(len(sentences))\n",
    "    return all_sentences, sentence_lengths\n",
    "\n",
    "\n",
    "# Load BERT model\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Collect all sentences\n",
    "all_sentences, sentence_lengths = collect_all_sentences(data)\n",
    "sentence_lengths = np.array(sentence_lengths)\n",
    "\n",
    "# Encode sentences\n",
    "sentence_embeddings = bert_encode(all_sentences, bert_model, tokenizer, device, batch_size=64)\n",
    "\n",
    "#free gpu memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': [array([-3.895567  , -0.7710196 , -1.379711  , ..., -4.317973  ,\n",
       "         -0.24954835, -0.5057722 ], dtype=float32),\n",
       "  array([ 0.29719004, -2.1620078 , -4.0901904 , ..., -1.0636894 ,\n",
       "         -0.65524375,  2.9486067 ], dtype=float32),\n",
       "  array([-4.715664 , -2.0460691, -1.6050384, ..., -6.1682596, -1.5817506,\n",
       "         -1.0122457], dtype=float32),\n",
       "  array([-0.8934293,  1.7406154,  2.1094537, ..., -6.358255 , -2.441966 ,\n",
       "          3.5570562], dtype=float32)],\n",
       " 'sentences': ['two buildings have been constructed on the bareland in the middle of the scene ',\n",
       "  'a huge building has been constructed on the green area at the corner of the scene ',\n",
       "  'two buildings have been constructed on the green area in the middle '],\n",
       " 'slider_values': [4, 2, 3]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features = []\n",
    "combined_labels = []\n",
    "slider_values = []\n",
    "\n",
    "for data_point in data:\n",
    "    for i in range(0, 4):\n",
    "        for j in range(1, 4):\n",
    "            slider_values.append(data_point[i][\"slider\" + str(j)])\n",
    "\n",
    "slider_values = np.array(slider_values)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming the following shapes\n",
    "# before_feature.shape = (2084, 2048)\n",
    "# after_feature.shape = (2084, 2048)\n",
    "# bert_encoded_sentences.shape = (6252, 768)\n",
    "# slider_values.shape = (6252,)\n",
    "\n",
    "# The number of sentences per image pair\n",
    "sentences_per_image_pair = sentence_embeddings.shape[0] // features_im1.shape[0]\n",
    "\n",
    "# Combining features\n",
    "combined_features = []\n",
    "for i in range(features_im1.shape[0]):\n",
    "    for j in range(sentences_per_image_pair):\n",
    "        sentence_index = i * sentences_per_image_pair + j\n",
    "        combined_feature = np.concatenate([features_im1[i], features_im2[i], sentence_embeddings[sentence_index]])\n",
    "        combined_features.append(combined_feature)\n",
    "\n",
    "combined_features = np.array(combined_features)\n",
    "\n",
    "# Check if the combined features align with the slider values\n",
    "assert combined_features.shape[0] == slider_values.shape[0]\n",
    "\n",
    "# Shuffle and split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, slider_values, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "combined_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if TensorFlow is able to recognize the GPU\n",
    "if tf.test.gpu_device_name():\n",
    "    print(f\"Default GPU Device: {tf.test.gpu_device_name()}\")\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer with L2 regularization\n",
    "model.add(Dense(4864, input_dim=4864, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Hidden layer with L2 regularization\n",
    "model.add(Dense(1024, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Another hidden layer with L2 regularization\n",
    "model.add(Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation=None))\n",
    "\n",
    "# Compile model with a custom learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mean_squared_error'])\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Summary\n",
    "model.summary()\n",
    "\n",
    "# Fit model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,  # Use either validation_split or validation_data\n",
    "    callbacks=[early_stop, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Sample And Get Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cümleler ve Modelin Tahmin Ettiği Ödüller:\n",
      "a blue roofed building has been constructed in the middle of the scene  - Tahmin Edilen Ödül: 0.00\n",
      "the white roofed building has changed its color of the scene  - Tahmin Edilen Ödül: 0.00\n",
      "The white roofed building has changed to the blue building in the middle of the scene  - Tahmin Edilen Ödül: 0.00\n",
      "\n",
      "Cümleler ve Gerçek Ödüller:\n",
      "a blue roofed building has been constructed in the middle of the scene  - Gerçek Ödül: -5.00\n",
      "the white roofed building has changed its color of the scene  - Gerçek Ödül: -5.00\n",
      "The white roofed building has changed to the blue building in the middle of the scene  - Gerçek Ödül: -5.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert model history into a Pandas DataFrame\n",
    "losses_df = pd.DataFrame(model.history.history)\n",
    "\n",
    "# Plot the losses and MSE on separate subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 10), sharex=True)\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(losses_df['loss'], label='Training Loss')\n",
    "axes[0].plot(losses_df['val_loss'], label='Validation Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# MSE plot\n",
    "axes[1].plot(losses_df['mean_squared_error'], label='Training MSE', linestyle='--')\n",
    "axes[1].plot(losses_df['val_mean_squared_error'], label='Validation MSE', linestyle='--')\n",
    "axes[1].set_title('Training and Validation MSE')\n",
    "axes[1].set_ylabel('MSE')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].legend()\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate MSE and MAE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "# Plotting the first N test samples for comparison\n",
    "N = 100  # Number of samples to visualize\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_test[:N], label='Actual')\n",
    "plt.plot(y_pred[:N], label='Predicted')\n",
    "plt.title('Comparison of Actual and Predicted Values')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Slider Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "requirements",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
